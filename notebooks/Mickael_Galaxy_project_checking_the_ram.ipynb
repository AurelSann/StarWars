{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = !ls ../raw_data/images_training_rev1/ #loading images_names.jpg to list\n",
    "df_image_names = pd.DataFrame(image_names)  \n",
    "df_image_names = df_image_names.rename(columns={0:'image'}) \n",
    "df_training_solutions_rev1 = pd.read_csv('../raw_data/training_solutions_rev1.csv')\n",
    "#loading y dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61578, 38)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_solutions_rev1['image'] = df_image_names['image']\n",
    "df_X_y = df_training_solutions_rev1.drop(columns=['GalaxyID'])\n",
    "df_X_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_y_sample = df_X_y.sample(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_y_train = df_X_y_sample[:200]\n",
    "df_X_y_test = df_X_y_sample[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def load_image(image):\n",
    "    '''returns one image'''\n",
    "    folder = f'../raw_data/images_training_rev1/{image}'\n",
    "    img = Image.open(folder)\n",
    "    img_array = np.array(img)\n",
    "    return np.resize(img_array, (224,224,3))\n",
    "    \n",
    "def load_images(df):\n",
    "    '''returns array of images'''\n",
    "    img_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        img = load_image(row[\"image\"])\n",
    "        img_list.append(img) \n",
    "    return np.stack(img_list)\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size=64, shuffle=True, ):\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.indices = self.df.index.tolist()\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        '''returns number of minibatches per epoch'''\n",
    "        return len(self.indices) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        '''shuffles the indices '''\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index)\n",
    "            \n",
    "    def __get_X_image(self, df):\n",
    "        '''returns images'''\n",
    "        X = load_images(df)\n",
    "        return X \n",
    "             \n",
    "    def __get_Y(self, df):\n",
    "        '''returns y'''\n",
    "        return np.array(df.drop(columns=[\"image\"]))\n",
    "    \n",
    "    def _get_data(self, batch):\n",
    "        '''returns batch of images and y'''\n",
    "        df_batch = self.df.query(\"index in @batch\") \n",
    "        X = self.__get_X_image(df_batch)\n",
    "        y = self.__get_Y(df_batch)\n",
    "        return X, y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''creates batches and returns final X and y'''\n",
    "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in index]\n",
    "        X, y = self._get_data(batch)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagenerator_train = DataGenerator(df=df_X_y_train, shuffle=True)\n",
    "datagenerator_test = DataGenerator(df=df_X_y_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import tensorflow.keras as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dense, Input, GlobalAveragePooling2D, Dropout, Concatenate, Conv2D, Flatten\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(224,224,3)))\n",
    "model.add(Conv2D(22, 22, activation='relu'))\n",
    "model.add(Conv2D(16, 16, activation='relu'))\n",
    "model.add(Conv2D(2, 2, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(37, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 203, 203, 22)      31966     \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 188, 188, 16)      90128     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 187, 187, 2)       130       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 69938)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 37)                2587743   \n",
      "=================================================================\n",
      "Total params: 2,709,967\n",
      "Trainable params: 2,709,967\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',  #loss a voir\n",
    "              optimizer='adam',\n",
    "              metrics='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 235s 69s/step - loss: 3.9940 - mse: 3.9940 - val_loss: 0.0717 - val_mse: 0.0717\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 174s 62s/step - loss: 0.0795 - mse: 0.0795 - val_loss: 0.0702 - val_mse: 0.0702\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 171s 61s/step - loss: 0.0796 - mse: 0.0796 - val_loss: 0.0696 - val_mse: 0.0696\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 171s 62s/step - loss: 0.0759 - mse: 0.0759 - val_loss: 0.0701 - val_mse: 0.0701\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 168s 61s/step - loss: 0.0768 - mse: 0.0768 - val_loss: 0.0689 - val_mse: 0.0689\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 200s 76s/step - loss: 0.0755 - mse: 0.0755 - val_loss: 0.0683 - val_mse: 0.0683\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 232s 84s/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0686 - val_mse: 0.0686\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 243s 86s/step - loss: 0.0751 - mse: 0.0751 - val_loss: 0.0678 - val_mse: 0.0678\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 204s 70s/step - loss: 0.0747 - mse: 0.0747 - val_loss: 0.0671 - val_mse: 0.0671\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 208s 74s/step - loss: 0.0740 - mse: 0.0740 - val_loss: 0.0663 - val_mse: 0.0663\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 192s 68s/step - loss: 0.0731 - mse: 0.0731 - val_loss: 0.0665 - val_mse: 0.0665\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 189s 67s/step - loss: 0.0727 - mse: 0.0727 - val_loss: 0.0657 - val_mse: 0.0657\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 190s 68s/step - loss: 0.0714 - mse: 0.0714 - val_loss: 0.0645 - val_mse: 0.0645\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 199s 72s/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.0647 - val_mse: 0.0647\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 194s 69s/step - loss: 0.0724 - mse: 0.0724 - val_loss: 0.0637 - val_mse: 0.0637\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 196s 69s/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0636 - val_mse: 0.0636\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 194s 70s/step - loss: 0.0704 - mse: 0.0704 - val_loss: 0.0635 - val_mse: 0.0635\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 193s 69s/step - loss: 0.0689 - mse: 0.0689 - val_loss: 0.0628 - val_mse: 0.0628\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 188s 67s/step - loss: 0.0690 - mse: 0.0690 - val_loss: 0.0620 - val_mse: 0.0620\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 187s 67s/step - loss: 0.0692 - mse: 0.0692 - val_loss: 0.0611 - val_mse: 0.0611\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 189s 68s/step - loss: 0.0685 - mse: 0.0685 - val_loss: 0.0610 - val_mse: 0.0610\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 190s 68s/step - loss: 0.0675 - mse: 0.0675 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 192s 69s/step - loss: 0.0690 - mse: 0.0690 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 190s 68s/step - loss: 0.0644 - mse: 0.0644 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 192s 69s/step - loss: 0.0651 - mse: 0.0651 - val_loss: 0.0590 - val_mse: 0.0590\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 191s 68s/step - loss: 0.0670 - mse: 0.0670 - val_loss: 0.0582 - val_mse: 0.0582\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 188s 67s/step - loss: 0.0653 - mse: 0.0653 - val_loss: 0.0585 - val_mse: 0.0585\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 185s 66s/step - loss: 0.0635 - mse: 0.0635 - val_loss: 0.0579 - val_mse: 0.0579\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 188s 67s/step - loss: 0.0634 - mse: 0.0634 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 187s 67s/step - loss: 0.0642 - mse: 0.0642 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 188s 67s/step - loss: 0.0630 - mse: 0.0630 - val_loss: 0.0567 - val_mse: 0.0567\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 188s 68s/step - loss: 0.0616 - mse: 0.0616 - val_loss: 0.0558 - val_mse: 0.0558\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 187s 66s/step - loss: 0.0605 - mse: 0.0605 - val_loss: 0.0559 - val_mse: 0.0559\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 187s 67s/step - loss: 0.0610 - mse: 0.0610 - val_loss: 0.0548 - val_mse: 0.0548\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 185s 66s/step - loss: 0.0620 - mse: 0.0620 - val_loss: 0.0539 - val_mse: 0.0539\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 187s 67s/step - loss: 0.0601 - mse: 0.0601 - val_loss: 0.0543 - val_mse: 0.0543\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 186s 66s/step - loss: 0.0606 - mse: 0.0606 - val_loss: 0.0538 - val_mse: 0.0538\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 184s 66s/step - loss: 0.0617 - mse: 0.0617 - val_loss: 0.0533 - val_mse: 0.0533\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 186s 66s/step - loss: 0.0593 - mse: 0.0593 - val_loss: 0.0532 - val_mse: 0.0532\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 185s 66s/step - loss: 0.0591 - mse: 0.0591 - val_loss: 0.0525 - val_mse: 0.0525\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 183s 66s/step - loss: 0.0584 - mse: 0.0584 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 189s 68s/step - loss: 0.0574 - mse: 0.0574 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 188s 67s/step - loss: 0.0583 - mse: 0.0583 - val_loss: 0.0513 - val_mse: 0.0513\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 188s 67s/step - loss: 0.0571 - mse: 0.0571 - val_loss: 0.0512 - val_mse: 0.0512\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 193s 70s/step - loss: 0.0561 - mse: 0.0561 - val_loss: 0.0509 - val_mse: 0.0509\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 191s 68s/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 192s 68s/step - loss: 0.0561 - mse: 0.0561 - val_loss: 0.0500 - val_mse: 0.0500\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 186s 66s/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0495 - val_mse: 0.0495\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 186s 66s/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0495 - val_mse: 0.0495\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 186s 66s/step - loss: 0.0554 - mse: 0.0554 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 187s 66s/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 185s 66s/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0488 - val_mse: 0.0488\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 183s 66s/step - loss: 0.0554 - mse: 0.0554 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 187s 67s/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0477 - val_mse: 0.0477\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 186s 66s/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0474 - val_mse: 0.0474\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 187s 66s/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 186s 67s/step - loss: 0.0520 - mse: 0.0520 - val_loss: 0.0469 - val_mse: 0.0469\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 187s 67s/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.0470 - val_mse: 0.0470\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 184s 66s/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 187s 67s/step - loss: 0.0513 - mse: 0.0513 - val_loss: 0.0461 - val_mse: 0.0461\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 185s 66s/step - loss: 0.0503 - mse: 0.0503 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 187s 66s/step - loss: 0.0517 - mse: 0.0517 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 63/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 187s 67s/step - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 186s 66s/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 185s 66s/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 185s 66s/step - loss: 0.0511 - mse: 0.0511 - val_loss: 0.0447 - val_mse: 0.0447\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 185s 66s/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 183s 65s/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0440 - val_mse: 0.0440\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 185s 66s/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 184s 66s/step - loss: 0.0483 - mse: 0.0483 - val_loss: 0.0435 - val_mse: 0.0435\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 185s 66s/step - loss: 0.0483 - mse: 0.0483 - val_loss: 0.0436 - val_mse: 0.0436\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 189s 67s/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 188s 68s/step - loss: 0.0486 - mse: 0.0486 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 186s 66s/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 186s 66s/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0425 - val_mse: 0.0425\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 184s 66s/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 183s 66s/step - loss: 0.0463 - mse: 0.0463 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 184s 66s/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0422 - val_mse: 0.0422\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 184s 66s/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 185s 66s/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 186s 66s/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 173s 61s/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 168s 60s/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 168s 60s/step - loss: 0.0457 - mse: 0.0457 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 169s 61s/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 172s 61s/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0400 - val_mse: 0.0400\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 171s 61s/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 171s 61s/step - loss: 0.0447 - mse: 0.0447 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 171s 61s/step - loss: 0.0469 - mse: 0.0469 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 170s 61s/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 167s 60s/step - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 168s 60s/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 167s 60s/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 170s 61s/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 171s 61s/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 171s 61s/step - loss: 0.0434 - mse: 0.0434 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 172s 61s/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 170s 61s/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 172s 61s/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 172s 61s/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 169s 60s/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 169s 60s/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 168s 60s/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 199s 75s/step - loss: 0.0422 - mse: 0.0422 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 215s 76s/step - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 172s 61s/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 172s 62s/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 172s 61s/step - loss: 0.0413 - mse: 0.0413 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 170s 61s/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 169s 60s/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 168s 60s/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 170s 61s/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 176s 61s/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0364 - val_mse: 0.0364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10d1058e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(patience=7, restore_best_weights=True )\n",
    "model.fit(datagenerator_train, batch_size=32, epochs=500, callbacks=es, verbose=1, validation_data=datagenerator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
