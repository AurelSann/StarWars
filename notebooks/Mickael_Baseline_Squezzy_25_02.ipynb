{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WJznm87CtTj",
    "outputId": "f9a4e595-c9ce-4015-9489-a4c9e10e6857"
   },
   "outputs": [],
   "source": [
    "!pip install gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ion3i3F2CuUE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import gcsfs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7GYZDkcCwWT",
    "outputId": "5fc017e4-7ee8-4781-c411-163ccc2dadb4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = !ls ../raw_data/images_training_rev1/ #loading images_names.jpg to list\n",
    "df_image_names = pd.DataFrame(image_names)  \n",
    "df_image_names = df_image_names.rename(columns={0:'image'}) \n",
    "df_training_solutions_rev1 = pd.read_csv('../raw_data/training_solutions_rev1.csv')\n",
    "#loading y dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JvzL1KC4CzI_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class1.1</th>\n",
       "      <th>Class1.2</th>\n",
       "      <th>Class1.3</th>\n",
       "      <th>Class2.1</th>\n",
       "      <th>Class2.2</th>\n",
       "      <th>Class3.1</th>\n",
       "      <th>Class3.2</th>\n",
       "      <th>Class4.1</th>\n",
       "      <th>Class4.2</th>\n",
       "      <th>Class5.1</th>\n",
       "      <th>...</th>\n",
       "      <th>Class10.1</th>\n",
       "      <th>Class10.2</th>\n",
       "      <th>Class10.3</th>\n",
       "      <th>Class11.1</th>\n",
       "      <th>Class11.2</th>\n",
       "      <th>Class11.3</th>\n",
       "      <th>Class11.4</th>\n",
       "      <th>Class11.5</th>\n",
       "      <th>Class11.6</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.383147</td>\n",
       "      <td>0.616853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616853</td>\n",
       "      <td>0.038452</td>\n",
       "      <td>0.578401</td>\n",
       "      <td>0.418398</td>\n",
       "      <td>0.198455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279952</td>\n",
       "      <td>0.138445</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325512</td>\n",
       "      <td>100008.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.327001</td>\n",
       "      <td>0.663777</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>0.031178</td>\n",
       "      <td>0.632599</td>\n",
       "      <td>0.467370</td>\n",
       "      <td>0.165229</td>\n",
       "      <td>0.591328</td>\n",
       "      <td>0.041271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131378</td>\n",
       "      <td>0.45995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100023.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class1.1  Class1.2  Class1.3  Class2.1  Class2.2  Class3.1  Class3.2  \\\n",
       "0  0.383147  0.616853  0.000000  0.000000  0.616853  0.038452  0.578401   \n",
       "1  0.327001  0.663777  0.009222  0.031178  0.632599  0.467370  0.165229   \n",
       "\n",
       "   Class4.1  Class4.2  Class5.1  ...  Class10.1  Class10.2  Class10.3  \\\n",
       "0  0.418398  0.198455       0.0  ...   0.279952   0.138445    0.00000   \n",
       "1  0.591328  0.041271       0.0  ...   0.000000   0.131378    0.45995   \n",
       "\n",
       "   Class11.1  Class11.2  Class11.3  Class11.4  Class11.5  Class11.6  \\\n",
       "0        0.0   0.092886        0.0        0.0        0.0   0.325512   \n",
       "1        0.0   0.591328        0.0        0.0        0.0   0.000000   \n",
       "\n",
       "        image  \n",
       "0  100008.jpg  \n",
       "1  100023.jpg  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_solutions_rev1['image'] = df_image_names['image']\n",
    "df_X_y = df_training_solutions_rev1.drop(columns=['GalaxyID'])\n",
    "df_X_y.head(2) #final dataframe with y and image_names.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 38)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_y_sample = df_X_y.sample(400)\n",
    "df_X_y_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 38)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_y_train = df_X_y_sample[:200]\n",
    "df_X_y_test = df_X_y_sample[200:]\n",
    "df_X_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnpATs9FC-5p",
    "outputId": "b5277687-3452-49b2-e5d3-d22ac36bdbf9"
   },
   "outputs": [],
   "source": [
    "# Matching the dataframe with the images in folder\n",
    "df = df.merge(df_Galaxy_ID, on='GalaxyID', how='inner')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdiwBR52DF9n",
    "outputId": "d2d792bb-0d22-485d-bae7-e101dd7c16d6"
   },
   "outputs": [],
   "source": [
    "N = 400\n",
    "df_X_y_sample = df_X_y.sample(N)\n",
    "df_X_y_train = df_X_y_sample[:int(N/2)]\n",
    "df_X_y_test = df_X_y_sample[int(N/2):]\n",
    "df_X_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LRivQihvDLUM"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def load_image(image):\n",
    "    '''returns one image'''\n",
    "    folder = f'../raw_data/images_training_rev1/{image}'\n",
    "    img = Image.open(folder)\n",
    "    img_array = np.array(img)\n",
    "    return np.resize(img_array, (224,224,3))\n",
    "    \n",
    "def load_images(df):\n",
    "    '''returns array of images'''\n",
    "    img_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        img = load_image(row[\"image\"])\n",
    "        img_list.append(img) \n",
    "    return np.stack(img_list)\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size=64, shuffle=True, ):\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.indices = self.df.index.tolist()\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        '''returns number of minibatches per epoch'''\n",
    "        return len(self.indices) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        '''shuffles the indices '''\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index)\n",
    "            \n",
    "    def __get_X_image(self, df):\n",
    "        '''returns images'''\n",
    "        X = load_images(df)\n",
    "        return X \n",
    "             \n",
    "    def __get_Y(self, df):\n",
    "        '''returns y'''\n",
    "        return np.array(df.drop(columns=[\"image\"]))\n",
    "    \n",
    "    def _get_data(self, batch):\n",
    "        '''returns batch of images and y'''\n",
    "        df_batch = self.df.query(\"index in @batch\") \n",
    "        X = self.__get_X_image(df_batch)\n",
    "        y = self.__get_Y(df_batch)\n",
    "        return X, y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''creates batches and returns final X and y'''\n",
    "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in index]\n",
    "        X, y = self._get_data(batch)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ql4D6L-PDNeI"
   },
   "outputs": [],
   "source": [
    "datagenerator_train = DataGenerator(df=df_X_y_train, shuffle=True)\n",
    "datagenerator_test = DataGenerator(df=df_X_y_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UwuJSoHDP50"
   },
   "outputs": [],
   "source": [
    "# import keras \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dense, Input, GlobalAveragePooling2D, Dropout, Concatenate, Conv2D, Flatten, MaxPool2D\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(224,224,3)))\n",
    "\n",
    "model.add(Conv2D(filters=254,kernel_size=(1,1), activation='relu'))\n",
    "model.add(Conv2D(filters=64,kernel_size=(1,1), activation='relu'))\n",
    "# model.add(Conv2D(16, 16, activation='relu'))\n",
    "# model.add(Conv2D(2, 2, activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(8,8),strides=(8,8)))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(200, activation='linear'))\n",
    "model.add(Dense(37, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mickaelkomendyak/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Input, GlobalAveragePooling2D, Dropout, Concatenate, Conv2D, Flatten, MaxPool2D\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "def fire_module(inputs,s1x1,e1x1,e3x3,name=\"fire\"):\n",
    "    w_init = tf.truncated_normal_initializer(mean=0.0, stddev=(1.0/int(inputs.shape[2])))\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "        #squeeze layer\n",
    "        squeeze_out = tf.layers.conv2d(inputs,filters=s1x1,kernel_size=1,strides=1,padding=\"VALID\",kernel_initializer=w_init)\n",
    "        relu_sq = tf.nn.relu(squeeze_out)\n",
    "    \n",
    "        #expand layer\n",
    "        k1_exp = tf.layers.conv2d(relu_sq,filters=e1x1,kernel_size=1,strides=1,padding=\"VALID\",kernel_initializer=w_init)\n",
    "        k1_relu = tf.nn.relu(k1_exp)\n",
    "        k3_exp = tf.layers.conv2d(relu_sq,filters=e3x3,kernel_size=3,strides=1,padding=\"SAME\",kernel_initializer=w_init)\n",
    "        k3_relu = tf.nn.relu(k3_exp)\n",
    "        \n",
    "        return tf.concat([k1_relu,k3_relu],axis=3)\n",
    "\n",
    "\"\"\"\n",
    "General Convolution Operation\n",
    "\"\"\"\n",
    "def general_conv(inputs,filters,kernel,stride=1,padding='VALID',name=\"conv\",relu = True,weight=\"Xavier\"):\n",
    "    if str(weight) == str(\"Xavier\"):\n",
    "        w_init = tf.truncated_normal_initializer(mean=0.0,stddev=(1.0/int(inputs.shape[2])))\n",
    "    else:\n",
    "        w_init = tf.truncated_normal_initializer(mean=0.0,stddev=0.01)\n",
    "        \n",
    "    with tf.variable_scope(name):\n",
    "        conv = tf.layers.conv2d(inputs,filters,kernel,stride,padding,kernel_initializer=w_init)\n",
    "        if relu == True:\n",
    "                conv = tf.nn.relu(conv)\n",
    "        return conv\n",
    "\n",
    "\"\"\"\n",
    "SqueezeNet Class Definition\n",
    "\"\"\"\n",
    "class SqueezeNet:\n",
    "    \n",
    "    def __init__(self,input_shape,out_classes,lr_rate,train):\n",
    "        self.lr_rate = tf.placeholder(tf.float32,name=\"lr_rate\")\n",
    "        self.out_classes = out_classes\n",
    "        self.inputs = tf.placeholder(tf.float32,shape=(None,input_shape[0],input_shape[1],input_shape[2]))\n",
    "        self.labels = tf.placeholder(tf.float32,shape=(None,self.out_classes))\n",
    "        self.loss_v0,self.loss_v0_res,self.loss_v1 = self.model_loss(self.inputs,self.labels,train)     \n",
    "        self.v0_opt,self.v0_res_opt,self.v1_opt = self.model_opti(self.loss_v0,self.loss_v0_res,self.loss_v1,self.lr_rate)\n",
    "        \n",
    "    #Model Definition of SqueezeNet V0\n",
    "    def model_arc_v0(self,inputs,train,reuse=False):\n",
    "        \n",
    "        with tf.variable_scope(\"squeezenet_v0\",reuse=reuse):\n",
    "            conv1 = general_conv(inputs,filters=96,kernel=7,stride=2,padding=\"SAME\",name=\"conv1\",relu=True,weight=\"Xavier\")\n",
    "            pool1 = tf.layers.max_pooling2d(conv1,pool_size=3,strides=2,name=\"pool1\")\n",
    "            \n",
    "            fire2 = fire_module(pool1,16,64,64,name=\"fire2\")\n",
    "            fire3 = fire_module(fire2,16,64,64,name=\"fire3\")\n",
    "            fire4 = fire_module(fire3,32,128,128,name=\"fire4\")\n",
    "        \n",
    "            pool2 = tf.layers.max_pooling2d(fire4,pool_size=3,strides=2,name=\"pool2\")\n",
    "            \n",
    "            fire5 = fire_module(pool2,32,128,128,name=\"fire5\")\n",
    "            fire6 = fire_module(fire5,48,192,192,name=\"fire6\")\n",
    "            fire7 = fire_module(fire6,48,192,192,name=\"fire7\")\n",
    "            fire8 = fire_module(fire7,64,256,256,name=\"fire8\")\n",
    "        \n",
    "            pool3 = tf.layers.max_pooling2d(fire8,pool_size=3,strides=2,name=\"pool3\")\n",
    "        \n",
    "            fire9 = fire_module(pool3,64,256,256,name=\"fire9\")\n",
    "            drop = tf.layers.dropout(fire9,rate=0.5,training=train)\n",
    "        \n",
    "            conv10 = general_conv(drop,filters=200,kernel=1,stride=1,padding=\"SAME\",name=\"conv10\",relu=True,weight=\"Gaussian\")\n",
    "        \n",
    "            avg_pool = tf.layers.average_pooling2d(conv10,pool_size=13,strides=1,name=\"pool_end\")\n",
    "            pool_shape = tf.shape(avg_pool)\n",
    "            logits = tf.reshape(avg_pool,shape=(pool_shape[0],pool_shape[3]))\n",
    "                    \n",
    "            return logits\n",
    "        \n",
    "    #Model Definiton of SqueezeNet V1    \n",
    "    def model_arc_v1(self,inputs,train,reuse=False):\n",
    "        \n",
    "        with tf.variable_scope(\"squeezenet_v1\",reuse=reuse):\n",
    "            conv1 = general_conv(inputs,filters=64,kernel=3,stride=2,padding=\"SAME\",name=\"conv1\",relu=True,weight=\"Xavier\")\n",
    "            pool1 = tf.layers.max_pooling2d(conv1,pool_size=3,strides=2,name=\"pool1\")\n",
    "            \n",
    "            fire2 = fire_module(pool1,16,64,64,name=\"fire2\")\n",
    "            fire3 = fire_module(fire2,16,64,64,name=\"fire3\")\n",
    "            \n",
    "            pool2 = tf.layers.max_pooling2d(fire3,pool_size=3,strides=2,name=\"pool2\")\n",
    "            \n",
    "            fire4 = fire_module(pool2,32,128,128,name=\"fire4\")\n",
    "            fire5 = fire_module(fire4,32,128,128,name=\"fire5\")\n",
    "            \n",
    "            pool3 = tf.layers.max_pooling2d(fire5,pool_size=3,strides=2,name=\"pool3\")\n",
    "            \n",
    "            fire6 = fire_module(pool3,48,192,192,name=\"fire6\")\n",
    "            fire7 = fire_module(fire6,48,192,192,name=\"fire7\")\n",
    "            fire8 = fire_module(fire7,64,256,256,name=\"fire8\")       \n",
    "            fire9 = fire_module(fire8,64,256,256,name=\"fire9\")\n",
    "            drop = tf.layers.dropout(fire9,rate=0.5,training=train)\n",
    "        \n",
    "            conv10 = general_conv(drop,filters=200,kernel=1,stride=1,padding=\"SAME\",name=\"conv10\",relu=True,weight=\"Gaussian\")\n",
    "        \n",
    "            avg_pool = tf.layers.average_pooling2d(conv10,pool_size=13,strides=1,name=\"pool_end\")\n",
    "        \n",
    "            pool_shape = tf.shape(avg_pool)\n",
    "            logits = tf.reshape(avg_pool,shape=(pool_shape[0],pool_shape[3]))\n",
    "        \n",
    "            return logits\n",
    "        \n",
    "        \n",
    "    #Model Definition of SqueezeNet V0 Residual     \n",
    "    def model_arc_v0_res(self,inputs,train,reuse=False):\n",
    "        \n",
    "        with tf.variable_scope(\"squeezenet_v0_res\",reuse=reuse):\n",
    "            conv1 = general_conv(inputs,filters=96,kernel=7,stride=2,padding=\"SAME\",name=\"conv1\",relu=True,weight=\"Xavier\")\n",
    "            pool1 = tf.layers.max_pooling2d(conv1,pool_size=3,strides=2,name=\"pool1\")\n",
    "            \n",
    "            fire2 = fire_module(pool1,16,64,64,name=\"fire2\")\n",
    "            fire3 = fire_module(fire2,16,64,64,name=\"fire3\")\n",
    "            \n",
    "            bypass_23 = tf.add(fire2,fire3,name=\"bypass_23\")\n",
    "            \n",
    "            fire4 = fire_module(bypass_23,32,128,128,name=\"fire4\")\n",
    "            pool2 = tf.layers.max_pooling2d(fire4,pool_size=3,strides=2,name=\"pool2\")\n",
    "            fire5 = fire_module(pool2,32,128,128,name=\"fire5\")\n",
    "            \n",
    "            bypass_45 = tf.add(pool2,fire5,name=\"bypass_45\")\n",
    "            \n",
    "            fire6 = fire_module(bypass_45,48,192,192,name=\"fire6\")\n",
    "            fire7 = fire_module(fire6,48,192,192,name=\"fire7\")\n",
    "            fire8 = fire_module(fire7,64,256,256,name=\"fire8\")\n",
    "        \n",
    "            pool3 = tf.layers.max_pooling2d(fire8,pool_size=3,strides=2,name=\"pool3\")\n",
    "        \n",
    "            fire9 = fire_module(pool3,64,256,256,name=\"fire9\")\n",
    "            \n",
    "            bypass_89 = tf.add(pool3,fire9,name=\"bypass_89\")\n",
    "            \n",
    "            drop = tf.layers.dropout(bypass_89,rate=0.5,training=train)\n",
    "        \n",
    "            conv10 = general_conv(drop,filters=200,kernel=1,stride=1,padding=\"SAME\",name=\"conv10\",relu=True,weight=\"Gaussian\")\n",
    "        \n",
    "            avg_pool = tf.layers.average_pooling2d(conv10,pool_size=13,strides=1,name=\"pool_end\")\n",
    "        \n",
    "            pool_shape = tf.shape(avg_pool)\n",
    "            logits = tf.reshape(avg_pool,shape=(pool_shape[0],pool_shape[3]))\n",
    "        \n",
    "            return logits\n",
    "\n",
    "\n",
    "    #Function to calculate loss \n",
    "    def model_loss(self,inputs,label,train):\n",
    "        logits_v0 = self.model_arc_v0(inputs,train)\n",
    "        logits_v0_res = self.model_arc_v0_res(inputs,train)\n",
    "        logits_v1 = self.model_arc_v1(inputs,train)\n",
    "        \n",
    "        loss_v0 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits_v0,labels=label))\n",
    "        loss_v0_res = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits_v0_res,labels=label))\n",
    "        loss_v1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits_v1,labels=label))\n",
    "        \n",
    "        return loss_v0,loss_v0_res,loss_v1\n",
    "    \n",
    "    #Function to calculate prediction form models\n",
    "    def model_prediction(self,inputs,train):\n",
    "        logits_v0 = self.model_arc_v0(inputs,train,True)\n",
    "        logits_v0_res = self.model_arc_v0_res(inputs,train,True)\n",
    "        logits_v1 = self.model_arc_v1(inputs,train,True)\n",
    "        \n",
    "        predict_v0 = tf.nn.softmax(logits_v0)\n",
    "        predict_v0_res = tf.nn.softmax(logits_v0_res)\n",
    "        predict_v1 = tf.nn.softmax(logits_v1)\n",
    "        \n",
    "        return predict_v0,predict_v0_res,predict_v1\n",
    "    \n",
    "    #Function to optimize the models. \n",
    "    def model_opti(self,loss_v0,loss_v0_res,loss_v1,lr_rate):\n",
    "        \n",
    "        train_vars = tf.trainable_variables()\n",
    "        v0_vars = [var for var in train_vars if var.name.startswith('squeezenet_v0')]\n",
    "        v0_res_vars = [var for var in train_vars if var.name.startswith('squeezenet_v0_res')]\n",
    "        v1_vars = [var for var in train_vars if var.name.startswith('squeezenet_v1')]        \n",
    "        \n",
    "        #Using Adam Optimizer \n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            v0_train_opt = tf.train.AdamOptimizer(lr_rate).minimize(loss_v0,var_list=v0_vars)\n",
    "            v0_res_train_opt = tf.train.AdamOptimizer(lr_rate).minimize(loss_v0_res,var_list=v0_res_vars)\n",
    "            v1_train_opt = tf.train.AdamOptimizer(lr_rate).minimize(loss_v1,var_list=v1_vars)\n",
    "            \n",
    "        return v0_train_opt, v0_res_train_opt, v1_train_opt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fire_module(inputs,s1x1,e1x1,e3x3,name=\"fire\"):\n",
    "    w_init = tf.truncated_normal_initializer(mean=0.0, stddev=(1.0/int(inputs.shape[2])))\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "        #squeeze layer\n",
    "        squeeze_out = tf.layers.conv2d(inputs,filters=s1x1,kernel_size=1,strides=1,padding=\"VALID\",kernel_initializer=w_init)\n",
    "        relu_sq = tf.nn.relu(squeeze_out)\n",
    "    \n",
    "        #expand layer\n",
    "        k1_exp = tf.layers.conv2d(relu_sq,filters=e1x1,kernel_size=1,strides=1,padding=\"VALID\",kernel_initializer=w_init)\n",
    "        k1_relu = tf.nn.relu(k1_exp)\n",
    "        k3_exp = tf.layers.conv2d(relu_sq,filters=e3x3,kernel_size=3,strides=1,padding=\"SAME\",kernel_initializer=w_init)\n",
    "        k3_relu = tf.nn.relu(k3_exp)\n",
    "        \n",
    "        return tf.concat([k1_relu,k3_relu],axis=3)\n",
    "\n",
    "    \n",
    "def squeezenet(inputs):\n",
    "            \n",
    "        \n",
    "            conv1 = tf.layers.conv2d((224,224,3),filters=96,strides=2, kernel_size=(2,2),name=\"conv1\")\n",
    "            pool1 = tf.layers.max_pooling2d(conv1,pool_size=3,strides=2,name=\"pool1\")\n",
    "            \n",
    "            fire2 = fire_module(pool1,16,64,64,name=\"fire2\")\n",
    "            fire3 = fire_module(fire2,16,64,64,name=\"fire3\")\n",
    "            \n",
    "            bypass_23 = tf.add(fire2,fire3,name=\"bypass_23\")\n",
    "            \n",
    "            fire4 = fire_module(bypass_23,32,128,128,name=\"fire4\")\n",
    "            pool2 = tf.layers.max_pooling2d(fire4,pool_size=3,strides=2,name=\"pool2\")\n",
    "            fire5 = fire_module(pool2,32,128,128,name=\"fire5\")\n",
    "            \n",
    "            bypass_45 = tf.add(pool2,fire5,name=\"bypass_45\")\n",
    "            \n",
    "            fire6 = fire_module(bypass_45,48,192,192,name=\"fire6\")\n",
    "            fire7 = fire_module(fire6,48,192,192,name=\"fire7\")\n",
    "            fire8 = fire_module(fire7,64,256,256,name=\"fire8\")\n",
    "        \n",
    "            pool3 = tf.layers.max_pooling2d(fire8,pool_size=3,strides=2,name=\"pool3\")\n",
    "        \n",
    "            fire9 = fire_module(pool3,64,256,256,name=\"fire9\")\n",
    "            \n",
    "            bypass_89 = tf.add(pool3,fire9,name=\"bypass_89\")\n",
    "            \n",
    "            drop = tf.layers.dropout(bypass_89,rate=0.5,training=train)\n",
    "        \n",
    "            conv10 = general_conv(drop,filters=200,kernel=1,stride=1,padding=\"SAME\",name=\"conv10\",relu=True,weight=\"Gaussian\")\n",
    "        \n",
    "            avg_pool = tf.layers.average_pooling2d(conv10,pool_size=13,strides=1,name=\"pool_end\")\n",
    "        \n",
    "            pool_shape = tf.shape(avg_pool)\n",
    "            logits = tf.reshape(avg_pool,shape=(pool_shape[0],pool_shape[3]))\n",
    "            \n",
    "            model = logits.compile(loss='mse',  #loss a voir\n",
    "              optimizer='adam',\n",
    "              metrics='mse')\n",
    "        \n",
    "            return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer conv1 expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor 'Const_6:0' shape=() dtype=int32>, <tf.Tensor 'Const_7:0' shape=() dtype=int32>, <tf.Tensor 'Const_8:0' shape=() dtype=int32>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-d5ad9afdf61d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqueezenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-a9dbbd52f9de>\u001b[0m in \u001b[0;36msqueezenet\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conv1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pooling2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pool1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(inputs, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[1;32m    435\u001b[0m       \u001b[0m_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m       _scope=name)\n\u001b[0;32m--> 437\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1720\u001b[0m                   \u001b[0;34m'will be removed in a future version. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m                   'Please use `layer.__call__` method instead.')\n\u001b[0;32m-> 1722\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_doc_inheritable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;31m# Eager execution on data tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m           with autocast_variable.enable_auto_cast_variables(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2085\u001b[0m     \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2087\u001b[0;31m       input_spec.assert_input_compatibility(\n\u001b[0m\u001b[1;32m   2088\u001b[0m           self.input_spec, inputs, self.name)\n\u001b[1;32m   2089\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     raise ValueError('Layer ' + layer_name + ' expects ' +\n\u001b[0m\u001b[1;32m    205\u001b[0m                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                      \u001b[0;34m'but it received '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer conv1 expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor 'Const_6:0' shape=() dtype=int32>, <tf.Tensor 'Const_7:0' shape=() dtype=int32>, <tf.Tensor 'Const_8:0' shape=() dtype=int32>]"
     ]
    }
   ],
   "source": [
    "model = squeezenet((224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ceK1xCZDUp0",
    "outputId": "e8a59053-2a21-4cd3-bbd3-ec7811a939f1"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qxDLMQ0UDWwo"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2ef4411c0077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.compile(loss='mse',  #loss a voir\n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               metrics='mse')\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse',  #loss a voir\n",
    "              optimizer='adam',\n",
    "              metrics='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FLhYJbHhDZOW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(patience=7, restore_best_weights=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKgcPJmVDdZn",
    "outputId": "79c02a5c-a2db-484f-dc52-1ac186289c88"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9eb7f012e169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagenerator_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatagenerator_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "model.fit(datagenerator_train, batch_size=2, epochs=100, callbacks=es, verbose=1, validation_data=datagenerator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckvWOtzxDh68"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of Salim_Baseline_Squezzy_25_02.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
